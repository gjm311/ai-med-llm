{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T14:44:36.248339Z",
     "start_time": "2024-11-28T14:44:36.081809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "client = OpenAI(api_key=\"***\")"
   ],
   "id": "f8c1e45463d7f482",
   "outputs": [],
   "execution_count": 447
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-28T14:44:38.038085Z",
     "start_time": "2024-11-28T14:44:36.966610Z"
    }
   },
   "source": [
    "\"\"\"Load data from results folder\"\"\"\n",
    "# Define the path to the results folder\n",
    "results_folder = 'results'\n",
    "\n",
    "# Open the pkl file and load its content\n",
    "with open(\"./results/tst_dict.pkl\", 'rb') as file:\n",
    "    tst_dict = pickle.load(file)"
   ],
   "outputs": [],
   "execution_count": 448
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:41:52.184883Z",
     "start_time": "2024-11-28T16:41:52.172607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_fid_dict(fid, tr_tst_dict):\n",
    "    fid_dict = {key: {fid: value[fid]} for key, value in tr_tst_dict.items() if fid in value.keys()}\n",
    "    return fid_dict\n",
    "\n",
    "def generate_patient_report(patient_data):\n",
    "    report_sections = []    \n",
    "    for category, instances in patient_data.items():\n",
    "        if category in ['cmr']: #, 'cmr', 'pt_status_event_update'\n",
    "            section = f\" {category.replace('_', ' ').title()} \\n\"\n",
    "            for patient_id, events in instances.items():\n",
    "                for event_id, event_data in events.items():\n",
    "                    if event_id != 1:\n",
    "                        continue\n",
    "                    # section += f\"\\n  Instance {event_id}:\\n\"\n",
    "                    for data_type, details in event_data.items():\n",
    "                        if data_type != 'metadata':\n",
    "                            for key, value in details.items():                                \n",
    "                                if 'Patient ID' in key:\n",
    "                                    section += f\" {key}: {value}\"#\\n\"\n",
    "                                if 'bsa' in key.lower():\n",
    "                                    continue\n",
    "                                if str(value) == 'nan':\n",
    "                                    continue\n",
    "                                if 'patient height' in key.lower():\n",
    "                                    section += f\" {key} {value}\\n\"\n",
    "                                    height = value\n",
    "                                if 'age at cmr' in key.lower(): \n",
    "                                    section += f\" {key} {round(value/365, 2)}\\n\"\n",
    "                                    age_at_cmr = value\n",
    "                                if 'patient weight' in key.lower():\n",
    "                                    weight = value\n",
    "                                section += f\" {key} {value}\\n\"\n",
    "            report_sections.append(section)\n",
    "    return \"\\n\".join(report_sections), weight, height, age_at_cmr\n",
    "\n",
    "def fetch_weight_ranges(weight, weight_range_perc=0.4):  \n",
    "    \"\"\"Generate weight ranges based on a given weight.\"\"\"\n",
    "    range_step = weight_range_perc * weight\n",
    "    min_range = weight - range_step\n",
    "    max_range = weight + range_step\n",
    "    num_ranges = 3\n",
    "    step_size = (max_range - min_range) / num_ranges\n",
    "    ranges = [\n",
    "        str(i + 1) + \". \" + str((round(min_range + i * step_size, 1),\n",
    "                                 round(min_range + (i + 1) * step_size, 1)))\n",
    "        for i in range(num_ranges)\n",
    "    ]\n",
    "    return ranges\n",
    "\n",
    "# Dynamically select a \"correct\" range for each example\n",
    "def assign_correct_range(weight_ranges):\n",
    "    \"\"\"Randomly assign a correct range.\"\"\"\n",
    "    correct_range = random.randint(1, len(weight_ranges))  # Random range between 1 and 5\n",
    "    correct_range_text = f\"Range {correct_range}\"\n",
    "    return correct_range, correct_range_text"
   ],
   "id": "e3757b9a8fe79cfa",
   "outputs": [],
   "execution_count": 458
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:41:53.146217Z",
     "start_time": "2024-11-28T16:41:53.130565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all patient keys\n",
    "patient_keys = list(tst_dict['cmr'].keys())\n",
    "\n",
    "# Ensure there are enough patients to form 50 unique triplets\n",
    "if len(patient_keys) < 60:\n",
    "    raise ValueError(\"Not enough patients to form 10 unique triplets.\")\n",
    "\n",
    "# Generate 10 unique sets of triplets\n",
    "triplets = [random.sample(patient_keys, 3) for _ in range(20)]\n",
    "\n",
    "output_report = {'prompt_num': [], 'fids': [], 'age_at_cmr': [], 'heights': [],\n",
    "                 'weights': [], 'weight_bands': [], 'response': [], 'real_answer': []}"
   ],
   "id": "7fd6d17a5fd35fde",
   "outputs": [],
   "execution_count": 459
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:30:42.106944Z",
     "start_time": "2024-11-26T00:27:39.373458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Creating report for triplets of pts\"\"\"\n",
    "for triple in triplets:\n",
    "    fid_dicts = []\n",
    "    for fid in triple:\n",
    "        fid_dicts.append(get_fid_dict(fid, tst_dict))\n",
    "    \n",
    "    fid_report1, weight1, height1, age1 = generate_patient_report(fid_dicts[0])\n",
    "    fid_report2, weight2, _, _ = generate_patient_report(fid_dicts[1])\n",
    "    fid_report3, weight3, _, _ = generate_patient_report(fid_dicts[2])\n",
    "    \n",
    "    output_report['prompt_num'].extend([\"1\", \"2\", \"3\"])\n",
    "    output_report['fids'].extend([triple, triple, triple])\n",
    "    output_report['age_at_cmr'].extend([age1, age1, age1])\n",
    "    output_report['heights'].extend([height1, height1, height1]) \n",
    "    output_report['weights'].extend([weight1, weight1, weight1])    \n",
    "    \n",
    "    fid1_ranges = fetch_weight_ranges(weight1)\n",
    "    fid2_ranges = fetch_weight_ranges(weight2)\n",
    "    fid3_ranges = fetch_weight_ranges(weight3)\n",
    "    \n",
    "    # Assign random correct ranges\n",
    "    fid1_correct_range, fid1_correct_text = assign_correct_range(fid1_ranges)\n",
    "    fid2_correct_range, fid2_correct_text = assign_correct_range(fid2_ranges)\n",
    "    fid3_correct_range, fid3_correct_text = assign_correct_range(fid3_ranges)\n",
    "    \n",
    "    # Convert ranges to formatted strings for the prompt\n",
    "    fid1_range_str = \" \".join(fid1_ranges)\n",
    "    fid2_range_str = \" \".join(fid2_ranges)\n",
    "    fid3_range_str = \" \".join(fid3_ranges)\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt_type1 = (\n",
    "        f\"You are given a report with a patient's age (in years) and height (in centimeters). \"\n",
    "        f\"Your task is to predict the patient's weight (in kilograms) for this patient {fid_report1}:\\n\"\n",
    "    )\n",
    "    \n",
    "    prompt_type2 = (\n",
    "        f\"You are given a report with a patient's age (in years) and height (in centimeters). \"\n",
    "        f\"Your task is to predict the patient's weight (in kilograms) by selecting one of the given ranges for this patient: {fid_report1}:\\n\"\n",
    "        f\"What is the correct weight range?\\n\\n{fid1_range_str}\"\n",
    "    )\n",
    "    \n",
    "    prompt_type3 = (\n",
    "        f\"You are given a report with a patient's age (in years) and height (in centimeters). \"\n",
    "        f\"Your task is to predict the patient's weight (in kilograms) by selecting one of the given ranges:\\n\\n\"\n",
    "        f\"Examples:\\n\"\n",
    "        f\"1. For this patient: {fid_report2}\\n\"\n",
    "        f\"   - Weight ranges: {fid2_range_str}\\n\"\n",
    "        f\"   Answer: {fid2_correct_text}\\n\\n\"\n",
    "        f\"2. For this patient {fid_report3}:\\n\"\n",
    "        f\"   - Weight ranges: {fid3_range_str}\\n\"\n",
    "        f\"   Answer: {fid3_correct_text}\\n\\n\"\n",
    "        f\"Now for this patient {fid_report1}:\\n\"\n",
    "        f\"What is the correct weight range?\\n\\n{fid1_range_str}\"\n",
    "    )\n",
    "    \n",
    "    chat_completion1 = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_type1}],\n",
    "    stream=False,\n",
    "    )\n",
    "    \n",
    "    chat_completion2 = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_type2}],\n",
    "        stream=False,\n",
    "    )\n",
    "    \n",
    "    chat_completion3 = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_type3}],\n",
    "        stream=False,\n",
    "    )\n",
    "    \n",
    "    resp1 = chat_completion1.choices[0].to_dict()   \n",
    "    resp2 = chat_completion2.choices[0].to_dict()\n",
    "    resp3 = chat_completion3.choices[0].to_dict()\n",
    "    \n",
    "    output_report['weight_bands'].extend([fid1_range_str, fid1_range_str, fid1_range_str])\n",
    "    output_report['response'].extend([resp1['message']['content'], resp2['message']['content'],  resp3['message']['content']])\n",
    "    output_report['real_answer'].extend([fid1_correct_text, fid1_correct_text, fid1_correct_text])"
   ],
   "id": "3b4cd389aa4ed5fe",
   "outputs": [],
   "execution_count": 430
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:31:11.173786Z",
     "start_time": "2024-11-26T00:31:11.150273Z"
    }
   },
   "cell_type": "code",
   "source": "# pd.DataFrame(output_report).to_csv('chatgpt4_reviews.csv', index=False)",
   "id": "c1d66eddea108a14",
   "outputs": [],
   "execution_count": 432
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d25c09f14c94a69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T17:39:40.526765Z",
     "start_time": "2024-11-28T17:39:40.502629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"After manual analysis of results, display results\"\"\"\n",
    "results = pd.read_csv('chatgpt4_reviews.csv')\n",
    "\n",
    "results_g1 = results[results['prompt_num'] == 1]\n",
    "results_g2 = results[results['prompt_num'] == 2]\n",
    "results_g3 = results[results['prompt_num'] == 3]\n",
    "\n",
    "\"\"\"After manual analysis of results, display results\"\"\"\n",
    "results = pd.read_csv('chatgpt4_reviews.csv')\n",
    "\n",
    "results_g1 = results[results['prompt_num'] == 1]\n",
    "results_g2 = results[results['prompt_num'] == 2]\n",
    "results_g3 = results[results['prompt_num'] == 3]\n",
    "\n",
    "g1_acc = results_g1[results_g1['human_assessment'] == 1].shape[0] / results_g1.shape[0]\n",
    "g2_acc = results_g2[results_g2['human_assessment'] == 1].shape[0] / results_g2.shape[0]\n",
    "g3_acc = results_g3[results_g3['human_assessment'] == 1].shape[0] / results_g3.shape[0]\n",
    "\n",
    "g1_venture = results_g1[results_g1['ventured_guess'] == 1].shape[0] / results_g1.shape[0]\n",
    "g2_venture = results_g2[results_g2['ventured_guess'] == 1].shape[0] / results_g2.shape[0]\n",
    "g3_venture = results_g3[results_g3['ventured_guess'] == 1].shape[0] / results_g3.shape[0]\n",
    "\n",
    "g1_acc_per_venture = results_g1[results_g1['human_assessment'] == 1].shape[0] / results_g1[results_g1['ventured_guess'] == 1].shape[0]\n",
    "g2_acc_per_venture = results_g2[results_g2['human_assessment'] == 1].shape[0] / results_g2[results_g2['ventured_guess'] == 1].shape[0]\n",
    "g3_acc_per_venture = results_g3[results_g3['human_assessment'] == 1].shape[0] / results_g3[results_g3['ventured_guess'] == 1].shape[0]\n",
    "\n",
    "print(f\"Results:\\nprompt 1 acc: {g2_acc:.2f}\\nprompt 2 acc: {g1_acc:.2f}\\nprompt 3 acc: {g3_acc:.2f}\\n\")\n",
    "print(f\"prompt 1 attempt perc: {g2_venture:.2f}\\nprompt 2 attempt perc: {g1_venture:.2f}\\nprompt 3 attempt perc: {g3_venture:.2f}\\n\")\n",
    "print(f\"prompt 1 acc per attempt: {g2_acc_per_venture:.2f}\\nprompt 2 acc per attempt: {g1_acc_per_venture:.2f}\\nprompt 3 acc per attempt: {g3_acc_per_venture:.2f}\")\n",
    "# results.columns"
   ],
   "id": "73ea672031939185",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "prompt 1 acc: 0.00\n",
      "prompt 2 acc: 0.05\n",
      "prompt 3 acc: 0.45\n",
      "\n",
      "prompt 1 attempt perc: 0.35\n",
      "prompt 2 attempt perc: 0.05\n",
      "prompt 3 attempt perc: 1.00\n",
      "\n",
      "prompt 1 acc per attempt: 0.00\n",
      "prompt 2 acc per attempt: 1.00\n",
      "prompt 3 acc per attempt: 0.45\n"
     ]
    }
   ],
   "execution_count": 463
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c7b6faa456e48d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8735032b2e4bd775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b04226ad7ae2e3fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
